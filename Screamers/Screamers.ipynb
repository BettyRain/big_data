{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Screamers\n",
    "Screamers: It is well known that WRITING IN ALL CAPS ONLINE IS A SUBSTITUTE FOR SCREAMING… OR YELLING. *cough!*. (Or some might say it’s simply cruise control for cooooool). Write a job to find users that scream a lot, and provide a screamer score (a highly-technical metric that you will invent).\n",
    "* For future reference (when we really want to get something off our chest), what are the top 5 subreddits for scream-y comments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import udf, col, desc\n",
    "from pyspark.sql.types import StructType, StructField, FloatType, LongType, StringType, BooleanType\n",
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "df = sqlContext.read.json(\"hdfs://orion11:15001/sampled_reddit/*\")\n",
    "columns = [\n",
    "    \"distinguished\",\n",
    "    \"downs\",\n",
    "    \"created_utc\",\n",
    "    \"controversiality\",\n",
    "    \"edited\",\n",
    "    \"gilded\",\n",
    "    \"author_flair_css_class\",\n",
    "    \"id\",\n",
    "    \"author\",\n",
    "    \"retrieved_on\",\n",
    "    \"score_hidden\",\n",
    "    \"subreddit_id\",\n",
    "    \"score\",\n",
    "    \"name\",\n",
    "    \"author_flair_text\",\n",
    "    \"link_id\",\n",
    "    \"archived\",\n",
    "    \"ups\",\n",
    "    \"parent_id\",\n",
    "    \"subreddit\",\n",
    "    \"body\"]\n",
    "\n",
    "df = df.select(\"author\", \"body\", \"subreddit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we make this filter a bit more rhobuts\n",
    "def filter_func(val):\n",
    "    res = re.search(r\"[^A-Z!@#$%^&*()>?\\\"\\'=-_+{}]+\", val)\n",
    "    return res==None\n",
    "\n",
    "filter_udf = udf(filter_func, BooleanType())\n",
    "\n",
    "df_filtered = df.filter(filter_udf(df[\"body\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-------------------+\n",
      "|              author|              body|          subreddit|\n",
      "+--------------------+------------------+-------------------+\n",
      "|          hubilation|NOOOOOOOOOOOOOOOOO|         reddit.com|\n",
      "|         tvreference|           PENCIL?|             gaming|\n",
      "|         frostysauce|          WINNING!|cripplingalcoholism|\n",
      "|    repulsethemonkey|         DAAAAANG!|               keto|\n",
      "|         sushiaddict|               O_O|               pics|\n",
      "|           Karl-Marx|            REPOST|             wowbro|\n",
      "|    HowardDeanScream|            BYEAH!|               pics|\n",
      "|             Nefandi|               LOL|           politics|\n",
      "|            fatmarik|       HYPERTONIC!|      todayilearned|\n",
      "|              eyyyyy|              BAMP|               pics|\n",
      "|          bizzybinnc|          FLAWLESS|           gonewild|\n",
      "|Ceci_Nest_Pas_Sparta|                 ?|               IAmA|\n",
      "|            lachiemx|            HAHAHA|          worldnews|\n",
      "|             Tatsumi|       BLOOOOOD!!!|          Minecraft|\n",
      "|          bearvivant|              EDC?|           LGBTrees|\n",
      "|               tas50|         HUMBOLDT!|               pics|\n",
      "|              Gnodab|                 ?|           Buddhism|\n",
      "|           RedSquidz|             DAMN!|                Art|\n",
      "|       Jesus_Faction|               KIN|          AskReddit|\n",
      "|                Nicd|              EVVK|          AskReddit|\n",
      "+--------------------+------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "screamers_count = df_filtered.groupBy('author').count()\n",
    "total_count = df.groupBy('author').count()\n",
    "\n",
    "# Rename cols, in prep for join\n",
    "screamers_count = screamers_count.withColumnRenamed(\"count\", \"scream_count\")\n",
    "total_count = total_count.withColumnRenamed(\"count\", \"total_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------+-----------+--------------------+\n",
      "|         author|scream_count|total_count|      screamer_score|\n",
      "+---------------+------------+-----------+--------------------+\n",
      "| atomicimploder|        1320|      17074| 0.07731053063136933|\n",
      "|yes_it_is_weird|         910|       1143|  0.7961504811898513|\n",
      "|    Sir_toolman|         748|        857|  0.8728121353558926|\n",
      "|    UnluckyLuke|         655|      17090| 0.03832650672908133|\n",
      "|   KingCaspianX|         494|       7511| 0.06577020370123818|\n",
      "|  TheNitromeFan|         491|      12853|  0.0382011981638528|\n",
      "|     bowloclock|         447|        514|  0.8696498054474708|\n",
      "|   redditmortis|         436|       2458|   0.177379983726607|\n",
      "|      Maniac_34|         385|       1807| 0.21306032097399003|\n",
      "|     davidjl123|         381|      17677|0.021553431012049557|\n",
      "+---------------+------------+-----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Join the two df's, and create the screamer score, \n",
    "# which for now is just the ration of screaming to not screaming\n",
    "\n",
    "\n",
    "joined_df = screamers_count.join(total_count, \"author\")\n",
    "joined_df = joined_df.withColumn(\"screamer_score\", (col(\"scream_count\")/ col(\"total_count\"))).orderBy([\"scream_count\", \"screamer_score\"], ascending=[False, False])\n",
    "\n",
    "# Throws out cases where all comments are screamers, to avoid bots\n",
    "# And [deleted] comments\n",
    "joined_df = joined_df.filter(\"scream_count != total_count\")\n",
    "joined_df = joined_df.filter(\"author != '[deleted]'\")\n",
    "joined_df.show(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Screamers\n",
    "The above shows the top 10 screamers, as sorted by the total number of screams, then the scream score that we assign them. Next we will show the sub-reddits with the most screamers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|      subreddit|count|\n",
      "+---------------+-----+\n",
      "|      AskReddit|69437|\n",
      "|       AskOuija|32103|\n",
      "|          funny|23764|\n",
      "|           pics|20616|\n",
      "|            nfl|18312|\n",
      "|leagueoflegends|18312|\n",
      "+---------------+-----+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subreddits_count = df_filtered.groupBy('subreddit').count()\n",
    "subreddits_count.orderBy(\"count\", ascending=False).show(n=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Angry Subreddit\n",
    "The graph above shows us the subreddits with the most screamers. The one subreddit that I would ignore from this table is \"AskOuija\", whih is a subbreddit where users work togeather to spell out words one letter at a time. Because these comments are only one letter, and don't seem to convey much anger, I did not think it belonged here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
