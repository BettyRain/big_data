{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.types import StructType, StructField, FloatType, LongType, StringType, IntegerType\n",
    "from  pyspark.sql.functions import input_file_name\n",
    "from pyspark.sql import SQLContext, Row\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.csv(\"hdfs://orion11:32001/final/sample.csv\",header=True,sep=\"\\t\");\n",
    "\n",
    "#hdfs://orion11:32001/final/sample.csv\n",
    "## bigget sample: hdfs://orion11:32001/final/bigger_sample.csv\n",
    "## all data:   hdfs://orion11:32001/nytimes_lead_paragraphs_Sep-1851-July-2017.csv\n",
    "\n",
    "##movie data: hdfs://orion11:32001/final/title.basics.tsv\n",
    "\n",
    "df = df.select(col(\"DATE\").alias(\"date\"), col(\"LEAD_PARAGRAPH\").alias(\"text\"))\n",
    "\n",
    "df.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"TEMP_DF\")\n",
    "df2 = spark.sql(\"\"\"select * from TEMP_DF WHERE temp_df.date LIKE '199%'\"\"\")\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#when have date and text columns\n",
    "#build sentimental analysis\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "def sentiment_analyzer_scores(sentence):\n",
    "    score = analyser.polarity_scores(sentence)\n",
    "    return str(score)\n",
    "\n",
    "pand = df2.toPandas()\n",
    "pand['analysis'] = pand['text'].apply(sentiment_analyzer_scores)\n",
    "pand = pand.drop(columns=['text'])\n",
    "\n",
    "pand.iloc[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{'neg': 0.171, 'neu': 0.721, 'pos': 0.108, 'co..\n",
    "#change columns to be able to count\n",
    "#group by year\n",
    "#count neg and pos for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json \n",
    "import numpy as np\n",
    "answer = []\n",
    "\n",
    "for row in pand.itertuples():\n",
    "    rows = row.analysis\n",
    "    rows = rows.replace(\"'\",'\"') \n",
    "    data = json.loads(rows)\n",
    "    columns = list(data.keys())\n",
    "    values = list(data.values())\n",
    "    arr_len = len(values)\n",
    "\n",
    "    res = pd.DataFrame(np.array(values, dtype=object).reshape(1, arr_len), columns=columns)\n",
    "    answer.append(res)\n",
    "    \n",
    "result = pd.concat(answer)\n",
    "\n",
    "print(result.iloc[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg          36674.9510\n",
      "neu         610741.9870\n",
      "pos          51654.6480\n",
      "compound     66411.9074\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(result.sum(axis = 0, skipna = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tconst: string (nullable = true)\n",
      " |-- titleType: string (nullable = true)\n",
      " |-- primaryTitle: string (nullable = true)\n",
      " |-- originalTitle: string (nullable = true)\n",
      " |-- isAdult: string (nullable = true)\n",
      " |-- startYear: string (nullable = true)\n",
      " |-- endYear: string (nullable = true)\n",
      " |-- runtimeMinutes: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfMovies = spark.read.csv(\"hdfs://orion11:32001/final/title.basics.tsv\",header=True,sep=\"\\t\");\n",
    "\n",
    "dfMovies.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------+\n",
      "|              genres|startYear|endYear|\n",
      "+--------------------+---------+-------+\n",
      "|Comedy,Fantasy,Ro...|     2001|     \\N|\n",
      "|              Comedy|     1951|   2016|\n",
      "|       Drama,Romance|     1952|   2009|\n",
      "|       Drama,Romance|     1952|   2009|\n",
      "|       Drama,Romance|     1956|   2010|\n",
      "|    Animation,Family|     1960|   2004|\n",
      "|    Animation,Family|     1960|   2004|\n",
      "|Comedy,Family,Fan...|     1964|   2004|\n",
      "|              Comedy|     1962|   2016|\n",
      "|    Animation,Family|     1965|   2003|\n",
      "|    Animation,Family|     1965|   2003|\n",
      "|       Short,Western|     2019|     \\N|\n",
      "|       Short,Western|     2019|     \\N|\n",
      "|Family,Fantasy,Music|     1968|   2001|\n",
      "|Family,Fantasy,Music|     1968|   2001|\n",
      "|       Drama,Romance|     1968|   2013|\n",
      "|Drama,Mystery,Rom...|     1970|   2011|\n",
      "|        Drama,Sci-Fi|     1970|   2016|\n",
      "|    Animation,Family|     1971|   2005|\n",
      "|    Animation,Family|     1971|   2005|\n",
      "+--------------------+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfMovies.createOrReplaceTempView(\"MOV_DF\")\n",
    "dfMovies2 = spark.sql(\"\"\"select mov_df.genres, mov_df.startYear, mov_df.endYear from MOV_DF WHERE mov_df.startYear LIKE '20%' OR mov_df.endYear LIKE '20%'\"\"\")\n",
    "dfMovies2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------+\n",
      "|              genres|startYear|endYear|\n",
      "+--------------------+---------+-------+\n",
      "|Comedy,Fantasy,Ro...|     2001|     \\N|\n",
      "|              Comedy|     1951|   2016|\n",
      "|       Drama,Romance|     1952|   2009|\n",
      "|       Drama,Romance|     1952|   2009|\n",
      "|       Drama,Romance|     1956|   2010|\n",
      "|    Animation,Family|     1960|   2004|\n",
      "|    Animation,Family|     1960|   2004|\n",
      "|Comedy,Family,Fan...|     1964|   2004|\n",
      "|              Comedy|     1962|   2016|\n",
      "|    Animation,Family|     1965|   2003|\n",
      "|    Animation,Family|     1965|   2003|\n",
      "|       Short,Western|     2019|     \\N|\n",
      "|       Short,Western|     2019|     \\N|\n",
      "|Family,Fantasy,Music|     1968|   2001|\n",
      "|Family,Fantasy,Music|     1968|   2001|\n",
      "|       Drama,Romance|     1968|   2013|\n",
      "|Drama,Mystery,Rom...|     1970|   2011|\n",
      "|        Drama,Sci-Fi|     1970|   2016|\n",
      "|    Animation,Family|     1971|   2005|\n",
      "|    Animation,Family|     1971|   2005|\n",
      "+--------------------+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfMovies2.createOrReplaceTempView(\"MOV2_DF\")\n",
    "dfMovies2 = spark.sql(\"\"\"select mov2_df.genres, mov2_df.startYear, mov2_df.endYear from MOV2_DF WHERE mov2_df.genres NOT LIKE '%\\\\N%'\"\"\")\n",
    "dfMovies2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------+\n",
      "|   genres|startYear|endYear|\n",
      "+---------+---------+-------+\n",
      "|   Comedy|     2001|     \\N|\n",
      "|  Fantasy|     2001|     \\N|\n",
      "|  Romance|     2001|     \\N|\n",
      "|   Comedy|     1951|   2016|\n",
      "|    Drama|     1952|   2009|\n",
      "|  Romance|     1952|   2009|\n",
      "|    Drama|     1952|   2009|\n",
      "|  Romance|     1952|   2009|\n",
      "|    Drama|     1956|   2010|\n",
      "|  Romance|     1956|   2010|\n",
      "|Animation|     1960|   2004|\n",
      "|   Family|     1960|   2004|\n",
      "|Animation|     1960|   2004|\n",
      "|   Family|     1960|   2004|\n",
      "|   Comedy|     1964|   2004|\n",
      "|   Family|     1964|   2004|\n",
      "|  Fantasy|     1964|   2004|\n",
      "|   Comedy|     1962|   2016|\n",
      "|Animation|     1965|   2003|\n",
      "|   Family|     1965|   2003|\n",
      "+---------+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split, explode\n",
    "dfMovies3 = dfMovies2.withColumn('genres',explode(split('genres',',')))\n",
    "dfMovies3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- genres: string (nullable = true)\n",
      " |-- startYear: string (nullable = true)\n",
      " |-- endYear: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfMovies3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "dfMovies4 = dfMovies3.groupBy(\"genres\").count().sort(desc(\"count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+\n",
      "|     genres|  count|\n",
      "+-----------+-------+\n",
      "|      Drama|1813285|\n",
      "|     Comedy|1477256|\n",
      "|      Short|1018883|\n",
      "|Documentary| 698311|\n",
      "|  Talk-Show| 648277|\n",
      "|    Romance| 614164|\n",
      "| Reality-TV| 486324|\n",
      "|     Family| 394810|\n",
      "|  Animation| 336641|\n",
      "|      Music| 305194|\n",
      "|     Action| 298191|\n",
      "|      Crime| 276681|\n",
      "|      Adult| 266926|\n",
      "|  Adventure| 243437|\n",
      "|  Game-Show| 215690|\n",
      "|    Fantasy| 154796|\n",
      "|      Sport| 149935|\n",
      "|     Horror| 142330|\n",
      "|    Mystery| 140207|\n",
      "|   Thriller| 132135|\n",
      "+-----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfMovies4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10169311\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F     \n",
    "\n",
    "c = dfMovies4.agg(F.sum(\"count\")).collect()[0][0]\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+--------------------+\n",
      "|     genres|  count|               total|\n",
      "+-----------+-------+--------------------+\n",
      "|      Drama|1813285|  0.1783095236245602|\n",
      "|     Comedy|1477256| 0.14526608538179234|\n",
      "|      Short|1018883|  0.1001919402405925|\n",
      "|Documentary| 698311| 0.06866846731307559|\n",
      "|  Talk-Show| 648277| 0.06374836997314764|\n",
      "|    Romance| 614164| 0.06039386542510107|\n",
      "| Reality-TV| 486324|0.047822708932788074|\n",
      "|     Family| 394810| 0.03882367251822665|\n",
      "|  Animation| 336641| 0.03310361931108214|\n",
      "|      Music| 305194|0.030011276083502608|\n",
      "|     Action| 298191| 0.02932263552565164|\n",
      "|      Crime| 276681|0.027207447977547348|\n",
      "|      Adult| 266926| 0.02624818928244008|\n",
      "|  Adventure| 243437|0.023938396613103877|\n",
      "|  Game-Show| 215690| 0.02120989317762039|\n",
      "|    Fantasy| 154796|0.015221876880351088|\n",
      "|      Sport| 149935|0.014743870061600044|\n",
      "|     Horror| 142330|0.013996031786224258|\n",
      "|    Mystery| 140207|0.013787266413624285|\n",
      "|   Thriller| 132135|0.012993505656381243|\n",
      "+-----------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#def count_per(num):\n",
    " #   return num/c\n",
    "\n",
    "#dfMovies5 = dfMovies4.withColumn('percentage', count_per(dfMovies4.count))\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "dfMovies4 = dfMovies4.withColumn('total', expr(\"count/10169311\"))\n",
    "\n",
    "\n",
    "dfMovies4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
