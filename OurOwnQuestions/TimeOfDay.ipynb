{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now that youâ€™ve found the answers to the questions above, design two of your own questions to answer. \n",
    "\n",
    "For the first question, We're going to be looking at the average time each comment was posted, to see which subreddits post the most during the day, and which have the most night owls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import udf, col, desc, explode, lower, mean, from_unixtime, split, count\n",
    "from pyspark.sql.types import StructType, StructField, FloatType, LongType, StringType, BooleanType, ArrayType, IntegerType\n",
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "df = sqlContext.read.json(\"hdfs://orion11:15001/sampled_reddit/*\")\n",
    "columns = [\n",
    "    \"distinguished\",\n",
    "    \"downs\",\n",
    "    \"created_utc\",\n",
    "    \"controversiality\",\n",
    "    \"edited\",\n",
    "    \"gilded\",\n",
    "    \"author_flair_css_class\",\n",
    "    \"id\",\n",
    "    \"author\",\n",
    "    \"retrieved_on\",\n",
    "    \"score_hidden\",\n",
    "    \"subreddit_id\",\n",
    "    \"score\",\n",
    "    \"name\",\n",
    "    \"author_flair_text\",\n",
    "    \"link_id\",\n",
    "    \"archived\",\n",
    "    \"ups\",\n",
    "    \"parent_id\",\n",
    "    \"subreddit\",\n",
    "    \"body\"]\n",
    "\n",
    "df = df.select(\"created_utc\", \"subreddit\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----+---+---+\n",
      "|        subreddit|hour|min|sec|\n",
      "+-----------------+----+---+---+\n",
      "|        AskReddit|  17|  0| 10|\n",
      "|        AskReddit|  17|  0| 12|\n",
      "|         politics|  17|  0| 16|\n",
      "|        AskReddit|  17|  0| 19|\n",
      "|             IAmA|  17|  0| 25|\n",
      "|       California|  17|  0| 28|\n",
      "|             pics|  17|  0| 32|\n",
      "|       reddit.com|  17|  0| 38|\n",
      "|        AskReddit|  17|  0| 34|\n",
      "|        AskReddit|  17|  0| 41|\n",
      "|           Frugal|  17|  0| 45|\n",
      "|           trance|  17|  0| 48|\n",
      "|           google|  17|  0| 48|\n",
      "|             IAmA|  17|  0| 55|\n",
      "|         sandiego|  17|  0| 57|\n",
      "|       googleplus|  17|  1|  4|\n",
      "|       technology|  17|  1|  8|\n",
      "|        worldnews|  17|  1|  5|\n",
      "|DrawingFromWithin|  17|  1|  1|\n",
      "|           gaming|  17|  1|  7|\n",
      "+-----------------+----+---+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert timestamp to string\n",
    "    # note: According to the docs, it should convert it to my local timezone\n",
    "time_df = df.withColumn('date_time', from_unixtime('created_utc', format=\"HH:mm:ss\"))\n",
    "\n",
    "split_col = split(time_df['date_time'], ':')\n",
    "time_df = time_df.withColumn('hour', split_col.getItem(0).cast(IntegerType()))\n",
    "time_df = time_df.withColumn('min', split_col.getItem(1).cast(IntegerType()))\n",
    "time_df = time_df.withColumn('sec', split_col.getItem(2).cast(IntegerType()))\n",
    "time_df = time_df.drop(\"created_utc\", \"date_time\")\n",
    "time_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now group by subreddit, and find the averages\n",
    "grouped_df = time_df.groupBy('subreddit').agg(mean('hour').cast(IntegerType()).alias(\"avg_hour\"), \n",
    "                                              mean('min').cast(IntegerType()).alias(\"avg_min\"), \n",
    "                                              mean('sec').cast(IntegerType()).alias(\"avg_sec\"), \n",
    "                                              count('subreddit').alias('num_posts'))\n",
    "\n",
    "# ignore small subreddits (50 fo sample_v3, 1000 for larger sample)\n",
    "grouped_df = grouped_df.filter(\"num_posts >= 1000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+-------+-------+---------+\n",
      "|           subreddit|avg_hour|avg_min|avg_sec|num_posts|\n",
      "+--------------------+--------+-------+-------+---------+\n",
      "|             alienth|      20|     13|     29|     1086|\n",
      "|              Oscars|      18|     29|     30|     1798|\n",
      "|             Toonami|      18|     29|     29|    45023|\n",
      "|      azdiamondbacks|      17|     29|     29|    12145|\n",
      "|          LAClippers|      17|     29|     29|    26708|\n",
      "|   secretsubgonewild|      17|     29|     28|     1101|\n",
      "|     LiveFromNewYork|      16|     30|     29|    20151|\n",
      "|                 agt|      16|     29|     29|     2386|\n",
      "|tamrielscholarsguild|      16|     29|     29|     5366|\n",
      "|            SFGiants|      16|     29|     29|   121490|\n",
      "|             Dodgers|      16|     29|     29|   124437|\n",
      "|     ColoradoRockies|      16|     29|     29|    12204|\n",
      "|            Mariners|      16|     29|     29|    73122|\n",
      "|       SanJoseSharks|      16|     29|     29|    30490|\n",
      "|       GekkoukanHigh|      16|     29|     29|     8768|\n",
      "|              Padres|      16|     29|     29|    18192|\n",
      "|               aldub|      16|     29|     29|     2139|\n",
      "|    OaklandAthletics|      16|     29|     29|    28763|\n",
      "|          MMAStreams|      16|     28|     29|     2473|\n",
      "|          nbastreams|      16|     27|     29|    12915|\n",
      "|      tucker_carlson|      16|     27|     28|     2015|\n",
      "| ColosseumTournament|      15|     30|     30|     1700|\n",
      "|       Weakendgunnit|      15|     30|     28|     2161|\n",
      "|          WahoosTipi|      15|     29|     29|    26153|\n",
      "|               kings|      15|     29|     29|    16378|\n",
      "+--------------------+--------+-------+-------+---------+\n",
      "only showing top 25 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display all the day people\n",
    "grouped_df.orderBy([\"avg_hour\", \"avg_min\", \"avg_sec\"], ascending=[False, False, False]).show(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------+-------+-------+---------+\n",
      "|        subreddit|avg_hour|avg_min|avg_sec|num_posts|\n",
      "+-----------------+--------+-------+-------+---------+\n",
      "|      nameaserver|       4|     25|     29|     5975|\n",
      "|     newonspotify|       4|     29|     29|     1085|\n",
      "|         BayStars|       6|     28|     29|     1666|\n",
      "|Suicidal_Insanity|       6|     29|     29|     1048|\n",
      "| VOCALOID_UTAU_jp|       6|     30|     29|     2465|\n",
      "|           hampan|       7|     29|     29|     7070|\n",
      "|            italy|       7|     29|     29|   119738|\n",
      "|            TV_ja|       7|     29|     29|     2088|\n",
      "|           france|       7|     29|     29|   188867|\n",
      "|         CasualUK|       7|     29|     29|     4912|\n",
      "|      Southampton|       7|     29|     29|     2405|\n",
      "|   F1FeederSeries|       7|     29|     29|     2733|\n",
      "|          belgium|       7|     29|     29|    43207|\n",
      "|             nanJ|       7|     30|     29|     1763|\n",
      "|       FreeEBOOKS|       8|     22|     29|     3253|\n",
      "|      gunnerkrigg|       8|     27|     29|     1576|\n",
      "|        HazardOps|       8|     28|     28|     1240|\n",
      "|   Motorsports_ja|       8|     28|     28|     1618|\n",
      "|        soccer_jp|       8|     28|     29|     2439|\n",
      "|       DanishEnts|       8|     29|     28|     1516|\n",
      "|          ukraina|       8|     29|     29|    64330|\n",
      "|       TheRedLion|       8|     29|     29|    19344|\n",
      "|           greece|       8|     29|     29|    26239|\n",
      "|           london|       8|     29|     29|    92035|\n",
      "|          Sverige|       8|     29|     29|     1879|\n",
      "+-----------------+--------+-------+-------+---------+\n",
      "only showing top 25 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display all the night owls\n",
    "grouped_df.orderBy([\"avg_hour\", \"avg_min\", \"avg_sec\"]).show(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "When I started this analysis, I think I went into it with a very naieve expectation. I though in the early morning I would see subreddits about insomnia, or about horror movies. Instead, I found an active community off redditors from other countries, which I had not even thought about when originally coming up with this question. For example, when diplaying the \"day people\", I saw subreddits for sports teams, starting with teams on the west coast (LA clippers, or The Warriors), moving towards east coast teams and cities as the time changed. Looking at what I thought would be \"night owls\", we saw subreddits for EU countries like France or Italy, along with some FC (soccer) subreddits.\n",
    "\n",
    "Not to be vulgar, but there was also not as much porn as I would have expected, though this may be because of my filter removing smaller subreddits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
