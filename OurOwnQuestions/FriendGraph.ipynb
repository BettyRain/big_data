{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now that youâ€™ve found the answers to the questions above, design two of your own questions to answer. \n",
    "\n",
    "For the second question, We're going to be looking for mentions of users in comments, to build a network of connected users, which I will then graph\n",
    "\n",
    "## Dependencies\n",
    "Note: this requires graphrames to do the pagerank. To use, simply add the flag `--packages graphframes:graphframes:0.7.0-spark2.4-s_2.11` when running pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from graphframes import *\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import udf, col, desc, explode, lower\n",
    "from pyspark.sql.types import StructType, StructField, FloatType, LongType, StringType, BooleanType, ArrayType\n",
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "df = sqlContext.read.json(\"hdfs://orion11:15001/sampled_reddit/*\")\n",
    "columns = [\n",
    "    \"distinguished\",\n",
    "    \"downs\",\n",
    "    \"created_utc\",\n",
    "    \"controversiality\",\n",
    "    \"edited\",\n",
    "    \"gilded\",\n",
    "    \"author_flair_css_class\",\n",
    "    \"id\",\n",
    "    \"author\",\n",
    "    \"retrieved_on\",\n",
    "    \"score_hidden\",\n",
    "    \"subreddit_id\",\n",
    "    \"score\",\n",
    "    \"name\",\n",
    "    \"author_flair_text\",\n",
    "    \"link_id\",\n",
    "    \"archived\",\n",
    "    \"ups\",\n",
    "    \"parent_id\",\n",
    "    \"subreddit\",\n",
    "    \"body\"]\n",
    "\n",
    "df = df.select(\"author\", \"body\", \"subreddit\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to find a mention in a given comment\n",
    "def find_mention(val):\n",
    "    found = re.findall(\"/u/([a-z0-9_-]+)\", val)\n",
    "    \n",
    "    if not found:\n",
    "        return None\n",
    "    \n",
    "    return found\n",
    "\n",
    "mention_udf = udf(find_mention, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+-------------------+------------------+\n",
      "|          author|                body|          subreddit|           mention|\n",
      "+----------------+--------------------+-------------------+------------------+\n",
      "|       sgspectra|I just stared at ...|fffffffuuuuuuuuuuuu|               [4]|\n",
      "|         freakie|I saw this post s...|         reddit.com|         [7266319]|\n",
      "|         redmoss|Hey, not bad for ...|                tf2|              [10]|\n",
      "|          rankun|If you pmed me.. ...|               pics|               [0]|\n",
      "|          cjhard|:O Too cool! I ha...|         reddit.com|         [1620808]|\n",
      "|       kappa-kun|I use [this](http...|            Android|         [5056709]|\n",
      "|           brash|Here's my [incine...|          Minecraft|            [7366]|\n",
      "|    sexbob-omb92|http://i41.servim...|               pics|             [f41]|\n",
      "|     nullfallacy|Go to your [**Pro...|         googleplus|               [0]|\n",
      "|        hazzypls|Awesome. [This is...|          starcraft|         [5506330]|\n",
      "|   necrosxiaoban|Link fail, sorry....|          starcraft|               [1]|\n",
      "|      red_player|http://www.youtub...|         philosophy|              [45]|\n",
      "|        elsewhat|Did a proof of co...|            Android|         [4379928]|\n",
      "|      meltmyface|I've [raced a nin...|               250r|         [2521113]|\n",
      "|wroughtironfence|[Menomena](http:/...|     ifyoulikeblank|               [1]|\n",
      "|        ex_ample|This is the \"real...|         googleplus|               [0]|\n",
      "|          ailish|https://plus.goog...|         reddit.com|               [0]|\n",
      "|kuatobaradanikto|Folk Bob Dylan:\n",
      "\n",
      "...|              Music|              [vw]|\n",
      "|            melp|Thanks for all th...|        photography|[6685760, 6685760]|\n",
      "|     spidersonic|I laughed hard, s...|              funny|             [f42]|\n",
      "+----------------+--------------------+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Finds the mentions\n",
    "df = df.withColumn(\"mention\", mention_udf(\"body\"))\n",
    "\n",
    "# filters out comments where there's no mention\n",
    "df = df.filter(col(\"mention\").isNotNull()) \n",
    "\n",
    "# Apparently we need to lowercase everything. Makes life easier later\n",
    "df = df.withColumn(\"author\", lower(col(\"author\")))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now start to create the edges and verticies for a graphframe\n",
    "v = df.select(\"author\").withColumnRenamed(\"author\", \"id\")\n",
    "\n",
    "e = df.select(\"author\", \"mention\").withColumn(\"single_mention\", explode(\"mention\"))\n",
    "e = e.withColumnRenamed(\"author\", \"src\").withColumnRenamed(\"single_mention\", \"dst\").drop(\"mention\")\n",
    "# Note: should we remove self mentions?\n",
    "\n",
    "# Finally create the graph\n",
    "g = GraphFrame(v, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate pageRank. Note: This takes FOREVER!\n",
    "results = g.pageRank(resetProbability=0.15, maxIter=10)\n",
    "display(results.vertices)\n",
    "\n",
    "# Save the pageRank, since it takes forever I don't want to have to run it multiple times\n",
    "results.vertices.write.parquet(\"hdfs://orion11:15001/friendgraph/gf/vertices\")\n",
    "results.edges.write.parquet(\"hdfs://orion11:15001/friendgraph/gf/edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the vertices and edges back.\n",
    "read_v = sqlContext.read.parquet(\"hdfs://orion11:15001/friendgraph/gf/vertices\")\n",
    "read_e = sqlContext.read.parquet(\"hdfs://orion11:15001/friendgraph/gf/edges\")\n",
    "\n",
    "final_g = GraphFrame(read_v, read_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_g.edges.show(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
