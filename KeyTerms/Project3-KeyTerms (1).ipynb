{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Terms\n",
    "Calculate the TF-IDF for a given subreddit.\n",
    "Produce a Tag Cloud of the terms (note: this doesnâ€™t have to be integrated into your code; simply including the image is enough).\n",
    "\n",
    "TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document).\n",
    "\n",
    "IDF(t) = log_e(Total number of documents / Number of documents with term t in it).\n",
    "\n",
    "TF-IDF = TF * IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------+----------------------+-----------------+--------------------+---------+----------------+-------+-----------+-------------+-----+------+------+-------+--------+-----------+----------+---------+--------------+-------+------------+-----+-----+------------+--------+---------+------------+---+------------+--------------------+\n",
      "|archived|    author|author_cakeday|author_flair_css_class|author_flair_text|                body|body_html|controversiality|created|created_utc|distinguished|downs|edited|gilded|     id| link_id|mod_reports|      name|parent_id|removal_reason|replies|retrieved_on|saved|score|score_hidden|stickied|subreddit|subreddit_id|ups|user_reports|            filename|\n",
      "+--------+----------+--------------+----------------------+-----------------+--------------------+---------+----------------+-------+-----------+-------------+-----+------+------+-------+--------+-----------+----------+---------+--------------+-------+------------+-----+-----+------------+--------+---------+------------+---+------------+--------------------+\n",
      "|    true|halftone84|          null|                  null|             null|I read the title ...|     null|               0|   null| 1309478410|         null|    0| false|     0|c22x4bc|t3_idgji|       null|t1_c22x4bc| t3_idgji|          null|   null|  1427302517| null|    1|       false|    null|AskReddit|    t5_2qh1i|  1|        null|hdfs://orion11:32...|\n",
      "|    true| keiyakins|          null|                  null|             null|Because you're ab...|     null|               0|   null| 1309478412|         null|    0| false|     0|c22x4bi|t3_idez1|       null|t1_c22x4bi| t3_idez1|          null|   null|  1427302517| null|    1|       false|    null|AskReddit|    t5_2qh1i|  1|        null|hdfs://orion11:32...|\n",
      "+--------+----------+--------------+----------------------+-----------------+--------------------+---------+----------------+-------+-----------+-------------+-----+------+------+-------+--------+-----------+----------+---------+--------------+-------+------------+-----+-----+------------+--------+---------+------------+---+------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.types import StructType, StructField, FloatType, LongType, StringType, IntegerType\n",
    "from  pyspark.sql.functions import input_file_name\n",
    "from pyspark.sql import SQLContext, Row\n",
    "\n",
    "df = sqlContext.read.json(\"hdfs://orion11:32001/sampled_reddit/*\")\n",
    "columns = [\n",
    "    \"distinguished\",\n",
    "    \"downs\",\n",
    "    \"created_utc\",\n",
    "    \"controversiality\",\n",
    "    \"edited\",\n",
    "    \"gilded\",\n",
    "    \"author_flair_css_class\",\n",
    "    \"id\",\n",
    "    \"author\",\n",
    "    \"retrieved_on\",\n",
    "    \"score_hidden\",\n",
    "    \"subreddit_id\",\n",
    "    \"score\",\n",
    "    \"name\",\n",
    "    \"author_flair_text\",\n",
    "    \"link_id\",\n",
    "    \"archived\",\n",
    "    \"ups\",\n",
    "    \"parent_id\",\n",
    "    \"subreddit\",\n",
    "    \"body\"]\n",
    "\n",
    "df = df.withColumn(\"filename\", input_file_name())\n",
    "df = df.withColumn(\"created_utc\", df[\"created_utc\"].cast(LongType()))\n",
    "df.show(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2288"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"TEMP_DF\")\n",
    "pd = spark.sql(\"\"\"select temp_df.filename, temp_df.body from TEMP_DF where temp_df.subreddit = 'gaming'\"\"\")\n",
    "\n",
    "#count number of documents\n",
    "number_of_docs = df.select(\"filename\").distinct().count()\n",
    "number_of_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                 doc|                text|\n",
      "+--------------------+--------------------+\n",
      "|hdfs://orion11:32...|           [deleted]|\n",
      "|hdfs://orion11:32...|Personally, I'm g...|\n",
      "|hdfs://orion11:32...|           [deleted]|\n",
      "+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pd = spark.sql(\"\"\"select temp_df.filename, first(temp_df.body) text from TEMP_DF GROUP BY temp_df.filename\"\"\").toDF(\"doc\",\"text\")\n",
    "pd.show(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>counted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hdfs://orion11:32001/sampled_reddit/part-00088...</td>\n",
       "      <td>{'': 2, 'deleted': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hdfs://orion11:32001/sampled_reddit/part-00329...</td>\n",
       "      <td>{'personally': 2, 'i': 3, 'm': 1, 'glad': 1, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hdfs://orion11:32001/sampled_reddit/part-00392...</td>\n",
       "      <td>{'': 2, 'deleted': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hdfs://orion11:32001/sampled_reddit/part-00669...</td>\n",
       "      <td>{'i': 1, 'm': 1, 'suddenly': 1, 'wondering': 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 doc  \\\n",
       "0  hdfs://orion11:32001/sampled_reddit/part-00088...   \n",
       "1  hdfs://orion11:32001/sampled_reddit/part-00329...   \n",
       "2  hdfs://orion11:32001/sampled_reddit/part-00392...   \n",
       "3  hdfs://orion11:32001/sampled_reddit/part-00669...   \n",
       "\n",
       "                                             counted  \n",
       "0                              {'': 2, 'deleted': 1}  \n",
       "1  {'personally': 2, 'i': 3, 'm': 1, 'glad': 1, '...  \n",
       "2                              {'': 2, 'deleted': 1}  \n",
       "3  {'i': 1, 'm': 1, 'suddenly': 1, 'wondering': 1...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def word_count(text):\n",
    "    word_count = {}\n",
    "    text = text.lower()\n",
    "    data = re.split(r'\\W+', text)\n",
    "    for word in data:\n",
    "        if word not in word_count:\n",
    "            word_count[word] = 1\n",
    "        else:\n",
    "            word_count[word] += 1\n",
    "    return word_count\n",
    "\n",
    "pand = pd.toPandas()\n",
    "pand['counted'] = pand['text'].apply(word_count)\n",
    "pand = pand.drop(columns=['text'])\n",
    "pand.iloc[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              2\n",
      "deleted       1\n",
      "personally    2\n",
      "i             3\n",
      "m             1\n",
      "Name: words, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "rows = []\n",
    "\n",
    "for row in pand.itertuples():\n",
    "    series = pd.Series(row.counted)\n",
    "    df = series.to_frame()\n",
    "    df['doc'] = row.doc \n",
    "    df.columns = ['words', 'doc']\n",
    "    df = pd.DataFrame(df)\n",
    "    rows.append(df)\n",
    "    \n",
    "result = pd.concat(rows)\n",
    "\n",
    "print(result['words'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Num</th>\n",
       "      <th>Doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>hdfs://orion11:32001/sampled_reddit/part-00088...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deleted</td>\n",
       "      <td>1</td>\n",
       "      <td>hdfs://orion11:32001/sampled_reddit/part-00088...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>personally</td>\n",
       "      <td>2</td>\n",
       "      <td>hdfs://orion11:32001/sampled_reddit/part-00329...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i</td>\n",
       "      <td>3</td>\n",
       "      <td>hdfs://orion11:32001/sampled_reddit/part-00329...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Words Num                                                Doc\n",
       "0               2  hdfs://orion11:32001/sampled_reddit/part-00088...\n",
       "1     deleted   1  hdfs://orion11:32001/sampled_reddit/part-00088...\n",
       "2  personally   2  hdfs://orion11:32001/sampled_reddit/part-00329...\n",
       "3           i   3  hdfs://orion11:32001/sampled_reddit/part-00329..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = pd.DataFrame(columns=['Words', 'Num', 'Doc'])\n",
    "\n",
    "for row in result.itertuples():\n",
    "    words = words.append({'Words': row.Index, 'Num': row.words, 'Doc': row.doc}, ignore_index=True)\n",
    "    \n",
    "words.iloc[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+--------------------+\n",
      "|      word|num|                file|\n",
      "+----------+---+--------------------+\n",
      "|          |  2|hdfs://orion11:32...|\n",
      "|   deleted|  1|hdfs://orion11:32...|\n",
      "|personally|  2|hdfs://orion11:32...|\n",
      "|         i|  3|hdfs://orion11:32...|\n",
      "|         m|  1|hdfs://orion11:32...|\n",
      "|      glad|  1|hdfs://orion11:32...|\n",
      "|        to|  4|hdfs://orion11:32...|\n",
      "|      hear|  1|hdfs://orion11:32...|\n",
      "|       you|  3|hdfs://orion11:32...|\n",
      "|        re|  2|hdfs://orion11:32...|\n",
      "+----------+---+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType\n",
    "schema = StructType([StructField(\"word\", StringType(), True), StructField(\"num\", IntegerType(), True), StructField(\"file\", StringType(), True)])\n",
    "dfNew = spark.createDataFrame(words, schema=schema)\n",
    "dfNew.show(n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-----------+\n",
      "|count(num)|     word|count(file)|\n",
      "+----------+---------+-----------+\n",
      "|       141|     some|        141|\n",
      "|        51|      few|         51|\n",
      "|        86|    still|         86|\n",
      "|        71|    those|         71|\n",
      "|         9|   online|          9|\n",
      "|        17|     hope|         17|\n",
      "|         3|   travel|          3|\n",
      "|         1|indicator|          1|\n",
      "|         1|  protoss|          1|\n",
      "|         4|   harder|          4|\n",
      "+----------+---------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfNew.createOrReplaceTempView(\"TEMP\")\n",
    "pd = spark.sql(\"\"\"SELECT COUNT(temp.num), temp.word, COUNT(temp.file)\n",
    "FROM TEMP\n",
    "GROUP BY temp.word\"\"\")\n",
    "pd.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11019"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_words = pd.select(\"word\").count()\n",
    "count_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "panda = pd.toPandas()\n",
    "panda.columns = ['appearance', 'word', 'files']\n",
    "\n",
    "saveToPic = panda.drop(columns=['files'])\n",
    "schema = StructType([StructField(\"num\", IntegerType(), True), StructField(\"word\", StringType(), True)])\n",
    "toPic = spark.createDataFrame(saveToPic, schema=schema)\n",
    "toPic.write.format('csv').save('hdfs://orion11:32001/key_terms_topic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.02561</td>\n",
       "      <td>still</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.03566</td>\n",
       "      <td>some</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01760</td>\n",
       "      <td>few</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.02238</td>\n",
       "      <td>those</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    result   word\n",
       "0  0.02561  still\n",
       "1  0.03566   some\n",
       "2  0.01760    few\n",
       "3  0.02238  those"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math \n",
    "\n",
    "col_names = ['result', 'appearance', 'word', 'files', 'TF', 'IDF']\n",
    "answerLast = pd.DataFrame(columns = col_names)\n",
    "\n",
    "for row in panda.itertuples():\n",
    "    TF = int(row.appearance)/count_words\n",
    "    IDF = math.log(number_of_docs/int(row.files))\n",
    "    result = TF*IDF\n",
    "    result = round(result, 5)\n",
    "    answerLast = answerLast.append({'result' : result, 'appearance': row.appearance, 'word': row.word, 'files': row.files, 'TF' : TF, 'IDF' : IDF }, ignore_index=True)\n",
    "\n",
    "answerLast = answerLast.drop(columns=['appearance', 'files', 'TF', 'IDF'])\n",
    "answerLast.iloc[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "answerLast.to_csv('key_terms_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
